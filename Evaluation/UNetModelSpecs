Model: "autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         [(None, 32, 72, 1)]       0
_________________________________________________________________
decoder (Functional)         (None, 32, 72, 1)         676609
=================================================================
Total params: 676,609
Trainable params: 676,161
Non-trainable params: 448
_________________________________________________________________
None
Model: "decoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         [(None, 32, 72, 1)]       0
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 36, 16)        160
_________________________________________________________________
leaky_re_lu (LeakyReLU)      (None, 16, 36, 16)        0
_________________________________________________________________
batch_normalization (BatchNo (None, 16, 36, 16)        64
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 8, 18, 32)         4640
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 8, 18, 32)         0
_________________________________________________________________
batch_normalization_1 (Batch (None, 8, 18, 32)         128
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 4, 9, 64)          18496
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 4, 9, 64)          0
_________________________________________________________________
batch_normalization_2 (Batch (None, 4, 9, 64)          256
_________________________________________________________________
flatten (Flatten)            (None, 2304)              0
_________________________________________________________________
dense (Dense)                (None, 128)               295040
_________________________________________________________________
dense_1 (Dense)              (None, 2304)              297216
_________________________________________________________________
reshape (Reshape)            (None, 4, 9, 64)          0
_________________________________________________________________
conv2d_transpose (Conv2DTran (None, 8, 18, 64)         36928
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 8, 18, 64)         0
_________________________________________________________________
batch_normalization_3 (Batch (None, 8, 18, 64)         256
_________________________________________________________________
conv2d_transpose_1 (Conv2DTr (None, 16, 36, 32)        18464
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 16, 36, 32)        0
_________________________________________________________________
batch_normalization_4 (Batch (None, 16, 36, 32)        128
_________________________________________________________________
conv2d_transpose_2 (Conv2DTr (None, 32, 72, 16)        4624
_________________________________________________________________
leaky_re_lu_5 (LeakyReLU)    (None, 32, 72, 16)        0
_________________________________________________________________
batch_normalization_5 (Batch (None, 32, 72, 16)        64
_________________________________________________________________
conv2d_transpose_3 (Conv2DTr (None, 32, 72, 1)         145
_________________________________________________________________
activation (Activation)      (None, 32, 72, 1)         0
=================================================================
Total params: 676,609
Trainable params: 676,161
Non-trainable params: 448
_________________________________________________________________
Layer name: input_1
Layer type: InputLayer
Output shape: [(None, 32, 72, 1)]
Trainable: True
--------------------------------------------------
Layer name: decoder
Layer type: Functional
Output shape: (None, 32, 72, 1)
Trainable: True
--------------------------------------------------